{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo object and attribute predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, set up Python, `numpy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sys\n",
    "import platform\n",
    "print(platform.python_version())\n",
    "sys.path.append('/home/dxwang/bottom-up-attention/caffe/python')\n",
    "import caffe\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from skimage import transform\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (12, 9)        # small images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dir to caffe root or prototxt database paths won't work wrong\n",
    "import os\n",
    "print os.getcwd()\n",
    "os.chdir('..')\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "sys.path.insert(0, './caffe/python/')\n",
    "sys.path.insert(0, './lib/')\n",
    "sys.path.insert(0, './tools/')\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '.../bottom-up-attention/data/genome/1600-400-20'\n",
    "\n",
    "# Load classes\n",
    "classes = ['__background__']\n",
    "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        classes.append(object.split(',')[0].lower().strip())\n",
    "\n",
    "# Load attributes\n",
    "attributes = ['__no_attribute__']\n",
    "with open(os.path.join(data_path, 'attributes_vocab.txt')) as f:\n",
    "    for att in f.readlines():\n",
    "        attributes.append(att.split(',')[0].lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named fast_rcnn.config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9aed4259f9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check object extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_get_blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named fast_rcnn.config"
     ]
    }
   ],
   "source": [
    "# Check object extraction\n",
    "from fast_rcnn.config import cfg, cfg_from_file\n",
    "from fast_rcnn.test import im_detect,_get_blobs\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "import cv2\n",
    "\n",
    "GPU_ID = 0   # if we have multiple GPUs, pick one \n",
    "caffe.set_device(GPU_ID)  \n",
    "caffe.set_mode_gpu()\n",
    "net = None\n",
    "cfg_from_file('.../bottom-up-attention/experiments/cfgs/faster_rcnn_end2end_resnet.yml')\n",
    "\n",
    "weights = '.../faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel'\n",
    "prototxt = '.../bottom-up-attention/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'\n",
    "\n",
    "net = caffe.Net(prototxt, caffe.TEST, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flickr30k_image_ids(split_name):\n",
    "    ''' Load a list of (path,image_id tuples). Modify this to suit your data locations. '''\n",
    "    assert split_name in ['flickr30K-train', 'flickr30K-val', 'flickr30K-test']\n",
    "    split_name = split_name.split('-')[-1]\n",
    "    IMAGES_DIR = 'multi30k-entities-dataset/data/images/flickr30k-images'\n",
    "    IMAGES_DIR += '/task1' if split_name == 'test' else ''\n",
    "    ANNOTS_DIR = os.path.join('data/Multi30K_DE/')\n",
    "    split = []  \n",
    "\n",
    "    with open(os.path.join(ANNOTS_DIR, '%s_images.txt' % split_name), 'r') as f:\n",
    "        items = [s.strip() for s in f.readlines()]\n",
    "        for i, item in enumerate(items):\n",
    "            filepath = os.path.join(IMAGES_DIR, item)\n",
    "            split.append((filepath, i))      \n",
    "    return split\n",
    "\n",
    "def load_ambiguouscoco_image_ids(split_name):\n",
    "    ''' Load a list of (path,image_id tuples). Modify this to suit your data locations. '''\n",
    "    IMAGES_DIR = '.../data/AmbiguousCOCO/translated_images'\n",
    "    IMAGES_DIR += '/task1' if split_name == 'test' else ''\n",
    "    ANNOTS_DIR = os.path.join('.../data/AmbiguousCOCO')\n",
    "    split = []  \n",
    "\n",
    "    with open(os.path.join(ANNOTS_DIR, 'image_list.txt'), 'r') as f:\n",
    "        items = [s.split('#')[0] for s in f.readlines()]\n",
    "        for i, item in enumerate(items):\n",
    "            filepath = os.path.join(IMAGES_DIR, item)\n",
    "            split.append((filepath, i))  \n",
    "    return split\n",
    "\n",
    "def get_obj_infos(im_file, visualization=False):\n",
    "    ###########################\n",
    "    # Similar to get_detections_from_im\n",
    "    conf_thresh = 0.4\n",
    "    min_boxes = 10\n",
    "    max_boxes = 20\n",
    "\n",
    "    im = cv2.imread(im_file)\n",
    "    scores, boxes, attr_scores, rel_scores = im_detect(net, im)\n",
    "\n",
    "    # Keep the original boxes, don't worry about the regression bbox outputs\n",
    "    rois = net.blobs['rois'].data.copy()\n",
    "    # unscale back to raw image space\n",
    "    blobs, im_scales = _get_blobs(im, None)\n",
    "    \n",
    "    cls_boxes = rois[:, 1:5] / im_scales[0]\n",
    "    cls_prob = net.blobs['cls_prob'].data\n",
    "    attr_prob = net.blobs['attr_prob'].data\n",
    "    pool5 = net.blobs['pool5_flat'].data\n",
    "\n",
    "    # Keep only the best detections\n",
    "    max_conf = np.zeros((rois.shape[0]))\n",
    "    \n",
    "    for cls_ind in range(1,cls_prob.shape[1]):\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = np.array(nms(dets, cfg.TEST.NMS))\n",
    "        max_conf[keep] = np.where(cls_scores[keep] > max_conf[keep], cls_scores[keep], max_conf[keep])\n",
    "    \n",
    "    keep_boxes = np.where(max_conf >= conf_thresh)[0]\n",
    "    keep_boxes = np.argsort(max_conf)[::-1][:max_boxes]\n",
    "    if len(keep_boxes) < min_boxes:\n",
    "        keep_boxes = np.argsort(max_conf)[::-1][:min_boxes]\n",
    "    elif len(keep_boxes) > max_boxes:\n",
    "        keep_boxes = np.argsort(max_conf)[::-1][:max_boxes]\n",
    "    ############################\n",
    "    boxes = cls_boxes[keep_boxes]\n",
    "    objects = np.argmax(cls_prob[keep_boxes][:,1:], axis=1)\n",
    "    attr_thresh = 0.1\n",
    "    attr = np.argmax(attr_prob[keep_boxes][:,1:], axis=1)\n",
    "    attr_conf = np.max(attr_prob[keep_boxes][:,1:], axis=1)\n",
    "    \n",
    "    \n",
    "    attrs = []\n",
    "    objs = []\n",
    "    attr_confs = []\n",
    "    objs_confs =  np.max(cls_prob[keep_boxes][:,1:], axis=1)\n",
    "    \n",
    "    \n",
    "    for i in range(len(keep_boxes)):\n",
    "        bbox = boxes[i]\n",
    "        if bbox[0] == 0:\n",
    "            bbox[0] = 1\n",
    "        if bbox[1] == 0:\n",
    "            bbox[1] = 1\n",
    "        cls = classes[objects[i]+1]\n",
    "        if attr_conf[i] > attr_thresh:\n",
    "            cls = attributes[attr[i]+1] + \" \" + cls\n",
    "            attr_confs.append(attr_conf[i])\n",
    "        objs.append(cls)\n",
    "            \n",
    "#     print('attrs = ', attrs)\n",
    "#     print('objs = ', objs)\n",
    "#     print('objs confs = ', objs_confs)\n",
    "#     print('cls_boxes =', cls_boxes)\n",
    "#     print 'boxes=%d' % (len(keep_boxes))\n",
    "    infors = {}\n",
    "    infors['obj_categories'] = objs\n",
    "    infors['obj_confs'] = objs_confs\n",
    "    infors['obj_boxes'] = boxes\n",
    "    infors['boxes'] = keep_boxes\n",
    "    infors['image_name'] = im_file\n",
    "    infors['features'] = pool5[keep_boxes]\n",
    "\n",
    "    \n",
    "    if visualization:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(im)\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=2, alpha=0.5)\n",
    "                )\n",
    "        plt.gca().text(bbox[0], bbox[1] - 2,\n",
    "                    '%s' % (cls),\n",
    "                    bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                    fontsize=10, color='white')\n",
    "    return infors\n",
    "\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "class JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, datetime):                                 \n",
    "            return obj.__str__()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "def save_dict(filename, dic):\n",
    "    '''save dict into json file'''\n",
    "    with open(filename,'w') as json_file:\n",
    "        json.dump(dic, json_file, ensure_ascii=False, cls=JsonEncoder)\n",
    "def save_dicts(filename, dic):\n",
    "    '''save dict into json file'''\n",
    "    with open(filename,'a+') as json_file:\n",
    "        json.dump(dic, json_file, ensure_ascii=False, cls=JsonEncoder)\n",
    "        json_file.write('\\n')\n",
    "def load_dict(filename):\n",
    "    '''load dict from json file'''\n",
    "    with open(filename,\"r\") as json_file:\n",
    "        dic = json.load(json_file)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n",
      "processing 0 ...\n"
     ]
    }
   ],
   "source": [
    "split_names = ['flickr30K-test']#, 'flickr30K-val', 'flickr30K-train']\n",
    "\n",
    "## multi30K\n",
    "for split_name in split_names:\n",
    "    im_files = load_flickr30k_image_ids(split_name)\n",
    "    file_num = len(im_files)\n",
    "    \n",
    "    save_file = '.../data/'+split_name+'.json'\n",
    "\n",
    "    if os.path.exists(save_file): os.remove(save_file)\n",
    "    \n",
    "    split_name = split_name.split('-')[-1]\n",
    "    for i, im_file in enumerate(im_files):\n",
    "        if i % 1000 == 0: print 'processing', float(i)/float(file_num), '...'\n",
    "        im_file = im_file[0]\n",
    "        info = get_obj_infos(im_file)\n",
    "#         features.append(info['features'])\n",
    "        save_dicts(save_file, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0.0 ...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## ambiguous\n",
    "im_files = load_ambiguouscoco_image_ids('')\n",
    "file_num = len(im_files)\n",
    "save_file = '.../data/ambiguou.json'\n",
    "if os.path.exists(save_file): os.remove(save_file)\n",
    "for i, im_file in enumerate(im_files):\n",
    "    if i % 1000 == 0: print 'processing', float(i)/float(file_num), '...'\n",
    "    im_file = im_file[0]\n",
    "    info = get_obj_infos(im_file)\n",
    "    save_dicts(save_file, info)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
