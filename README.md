# OVC-MMT
Source code of AAAI-OVC.

This code repository highly depends on the research [A Visual Attention Grounding Neural Model for Multimodal Machine Translation](https://arxiv.org/abs/1808.08266) and its open-source pytorch implementation [Eurus-Holmes/VAG-NMT](https://github.com/Eurus-Holmes/VAG-NMT).

## Checkpoints

link: [[baidu]](https://pan.baidu.com/s/1KHEkKK6wKOzSmxVxkylRzQ) 

password: ovc0

## Data 

- raw data for similarity searching in scripts/raw_data: 

  link: [[baidu]](https://pan.baidu.com/s/1sw-yGQWUi9qHbyuIfU7SpQ)
  password: ovc0

- data of Multi30K and Ambiguous:

  link: too large, updating

  